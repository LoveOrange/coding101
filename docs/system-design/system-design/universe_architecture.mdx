---
sidebar_position: 3
tags:
  - system design
  - interview
draft: false
---

import singleAppImg from './assets/universe_architecture/single_app.png';
import multiInstanceImg from './assets/universe_architecture/multi_instance.png';
import readWriteSeparationImg from './assets/universe_architecture/read_write_separation.png';
import cacheImg from './assets/universe_architecture/cache.png';
import asyncWriteImg from './assets/universe_architecture/async_write.png';
import loadBalancerImg from './assets/universe_architecture/load_balancer.png';

# 系统设计的通用架构

:::tip 基本架构
本文根据常见的系统设计面试题目，以及我的实际经验，涉及了一个较为通用的系统设计架构图。

除了可以用来解决系统设计面试的问题之外，也可以作为真实系统设计的一个基本模板。
:::

:::tip 架构演进
除了了解系统设计的基本组件之外，更重要的是了解到架构的演进过程，从简单的单体应用，一步一步成长为复杂的分布式系统。
:::

本文将从一个最基本的单体应用出发，假设当流量增加时，如何一步一步处理掉系统的瓶颈，最终让系统成长为一个可以承载百万用户的分布式系统。

## 1. 用例与基本约束

### 1.1. 用例

作为一个模拟的服务，我们不设置具体的业务场景，简单地将用例定义为：

1. 用户写入某些内容
2. 用户读取某些内容

这也与绝大多数的使用场景相似。大家可以思考下，是否遇到的大多数需求，都可以抽象为「写入」与「读取」呢？

虽然用例很简单，但是随着用户量的增长，不论是「写入」还是「读取」，都会遇到性能的瓶颈。

### 1.2. 基本约束

因为本文重点想要讨论系统设计的演进过程，所以我们会将最终目标定义为「百万用户」。

但是没有服务会在一开始就拥有百万用户，所以我们会讨论随着用户量的增加，通常哪里会最先出现瓶颈，以及如何解决这些瓶颈。

## 2. 架构设计

### 2.1. 单体应用

千里之行，始于足下。

在用户量不多时，我们通常使用一个单体服务解决所有的需求。

这样做的好处是：

1. 不必在一开始就讨论复杂的分布式一致性问题
2. 简单的架构有助于项目早期的快速迭代

在单体应用中，我们通过一个服务处理所有的请求。但是并不意味着系统中只有一个组件，一些基本的组件如「Web Server」、「Database」等都是必不可少的。

<div style={{textAlign: 'center'}}>
  <img src={singleAppImg} alt="单体应用" style={{width: '30%'}} />
</div>

虽然能满足基本的需求，但是在讨论用户增加之前，图中有一个显而易见的问题，那就是「单点故障」。

### 2.2. 多实例

为了解决单点故障的问题，我们通常会为每个组件部署「多实例」，即使一个实例宕机，也不会影响其他组件的正常工作。

<div style={{textAlign: 'center'}}>
  <img src={multiInstanceImg} alt="多实例" style={{width: '30%'}} />
</div>

如上图所示，我们为每个组件都添加了一个新的实例，表示该组件有多个节点。

到此为止我们的单体应用正式向分布式系统演进。

:::info 多实例的复杂性
需要注意的是，虽然在架构图中每一个组件都有了多个实例，但是在实际开发中，如何在不同的实例间通信、分发流量、保证一致性等，是十分复杂的话题。

多实例可以通过「主备切换」、「服务发现」、「请求的负载均衡」等技术来实现，本站会出相关的专题来讨论这些不同的实现。
:::

### 2.3. 读写分离

让我们逐步增加用户数量。接下来我们会逐渐意识到两个问题：

> 1. **「写请求」总是比「读请求」耗费更长的时间与资源**
> 2. **「读请求」总是比「写请求」更多**

因为在分布式系统中，为了保证数据的「**一致性**」，写请求要经历以下过程：

1. 等待所有节点同步此请求（取决于使用的分布式一致性协议，通常由数据库去做这件事）
2. 最终写入到数据存储的**磁盘**上

当用户增长时，「写请求」与「读请求」会抢占同一个节点的资源，当写请求阻塞时，读请求也会被阻塞。

接下来要做的，就是将「写请求」与「读请求」分离，使用不同的节点去处理不同类型的请求。

同样的压力也存在于数据库中，因此对数据库也进行「读写分离」。另外为了承载更多的用户，数据库也需要考虑到「分库分表」的问题，来减少单一数据库实例或者数据表的压力。

:::info 读写分离
本文的用户场景只有「写入」与「读取」，所以分离出「写服务」与「读服务」足够满足基本需求。

实际的面试与工作中，可以根据业务场景详细划分出不同的组件，如「用户服务」、「订单服务」等等。
:::

<div style={{textAlign: 'center'}}>
  <img src={readWriteSeparationImg} alt="读写分离" style={{width: '50%'}} />
</div>

### 2.4. 缓存

上一节我们提到了，为了保证一致性，需要将数据最终写入到「**磁盘**」上。

从磁盘中获取数据的延迟，要远高于从内存中获取数据。即使在数据库读写分离的情况，大量的读请求依然会是数据库处于高负载状态。

为了解决这个问题，我们可以在数据库与服务之间添加一个「**缓存**」层。

当读请求到来时，首先查询缓存，如果缓存中存在，则直接返回缓存中的数据。

如果缓存中不存在，则查询数据库，并将数据写入到缓存中。

<div style={{textAlign: 'center'}}>
  <img src={cacheImg} alt="缓存" style={{width: '50%'}} />
</div>

### 2.5. 异步写入

处理了读请求的延迟问题，我们再来看写入。

写入会面临比读取更多的压力：

1. 写入延迟：由于分布式系统的同步问题，写入有着比读取更长的执行时间，这也意味着更长的延迟与更多的资源占用
2. 大量写入：随着用户增长，短时间会涌入大量的写入请求，这会瞬间增加数据库的压力。一旦一个线程阻塞，可能会导致所有请求都阻塞，甚至服务宕机

为了解决这个问题，我们可以使用「**异步写入**」。写入服务接受「写请求」后，将「写请求」添加到「**消息队列**」中，之后就可以响应给用户，如正在处理写请求等。

同时，有另一个服务从消息队列中读取「写请求」，执行真实的写入操作。该服务可以根据自己的处理能力，决定每次读取多少条消息，避免资源耗尽导致的写请求阻塞。

此时的消息队列相当于一个蓄水池，可以缓冲大量的写请求，避免大量写请求导致资源耗尽；同时也可以分散写入压力，避免服务宕机。

<div style={{textAlign: 'center'}}>
  <img src={asyncWriteImg} alt="异步写入" style={{width: '70%'}} />
</div>

### 2.6. 负载均衡

此时，我们已经通过缓存降低了「读请求」的延迟，也通过异步写入降低了「写请求」的负载。可以说我们已经有了相对健壮的后端服务。

让我们再来看看服务的入口，也就是「**Web Server**」。

架构图中的 Web Server 是一个比较宽泛的概念，主要指处理「HTTP」请求的组件。在我们分离了读写请求之后，Web Server 也要具备「反向代理」的功能。

在实际生产环境中，Web Server 通常会使用「Nginx」。当然在系统设计面试中，我们依然可以使用「Web Server」来替代。

最后讨论 Web Server 的瓶颈，是因为 Web Server 通常具备极佳的性能，它出现瓶颈的时机会比后端服务晚很多。

另外在流量经过业务服务前，通常有两个环节：

1. **负载均衡（Load Balancer）**：主要做流量分发、健康检查、流量控制等等，可以理解是流量从「用户」 -> 「数据中心」
2. **反向代理（Reverse Proxy）**：处理具体的请求，分发到实际的业务服务中，可以理解是流量进一步分发到「业务服务」

因此这里我们也会在 Web Server 的基础上，再添加一个「Load Balancer」组件。

另外，即使有了缓存，如果存在大量的读请求也会为后端服务带来较高的负载。如果用户读取的内容大部分都是静态资源，我们可以将静态资源保存在「内容分发网络（CDN）」中。

<div style={{textAlign: 'center'}}>
  <img src={loadBalancerImg} alt="负载均衡" style={{width: '70%'}} />
</div>

至此，我们将一个单体应用，扩展为了可以承载百万用户的系统。确保了每一个节点的高可用，已经针对常见的性能瓶颈，都做了充分地优化。

## 3. 总结

本文列举了一个最基本的使用场景，分析随着用户量的增加，系统会在哪里优先出现瓶颈，并且一步一步地优化瓶颈，最终扩展为一个可以承载百万用户的系统。

当然实际的业务场景要更为复杂，可能还会面对以下问题：

1. 业务要远比基本的「写入」与「读取」复杂，此时需要根据业务需求，增加不同的微服务
2. 搜索请求。搜索作为一个常见的场景，通常会引入 Elasticsearch 等组件保存数据，实际与异步写入 Database 类似，大家可以自行尝试

除了最终的架构之外，更重要的是架构如何从最初的单体应用演进到最终的分布式架构，了解了每一个瓶颈点的发生原因与解决方法，相信大家可以更得心应手地面对系统设计的面试。
